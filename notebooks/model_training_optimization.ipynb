{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfac77fc-5261-4aff-96eb-51ff58135ed5",
   "metadata": {},
   "source": [
    "# Titanic Passenger Survival Prediction\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This project focuses on predicting whether a passenger survived the sinking of the Titanic based on various features like ticket class, age, gender, and family relations aboard the ship. The dataset provides detailed information about each passenger, enabling the use of classification models to predict survival outcomes. This project demonstrates the use of machine learning classification techniques on one of the most famous datasets in the field of data science.\n",
    "\n",
    "## Source\n",
    "\n",
    "This dataset is vailable on Kaggle in the following link:\n",
    "\n",
    "> https://www.kaggle.com/c/titanic/data\n",
    "\n",
    "## Data Dictionary\n",
    "\n",
    "The dataset contains the following columns:\n",
    "\n",
    "- **survival**: Survival (0 = No, 1 = Yes)\n",
    "- **pclass**: Ticket class (1 = 1st, 2 = 2nd, 3 = 3rd)\n",
    "- **sex**: Gender of the passenger\n",
    "- **age**: Age of the passenger in years\n",
    "- **sibsp**: Number of siblings/spouses aboard the Titanic\n",
    "- **parch**: Number of parents/children aboard the Titanic\n",
    "- **ticket**: Ticket number\n",
    "- **fare**: Passenger fare\n",
    "- **cabin**: Cabin number\n",
    "- **embarked**: Port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)\n",
    "\n",
    "### Variable Notes\n",
    "\n",
    "- **pclass**: A proxy for socio-economic status (SES)\n",
    "  - 1st = Upper class\n",
    "  - 2nd = Middle class\n",
    "  - 3rd = Lower class\n",
    "\n",
    "- **age**: Age is fractional if less than 1. If the age is estimated, it is in the form of `xx.5`.\n",
    "\n",
    "- **sibsp**: Number of siblings/spouses aboard the Titanic.\n",
    "  - Sibling = brother, sister, stepbrother, stepsister\n",
    "  - Spouse = husband, wife (mistresses and fianc√©s were ignored)\n",
    "\n",
    "- **parch**: Number of parents/children aboard the Titanic.\n",
    "  - Parent = mother, father\n",
    "  - Child = daughter, son, stepdaughter, stepson\n",
    "  - Some children traveled only with a nanny, therefore `parch=0` for them.\n",
    "\n",
    "## Objective\n",
    "\n",
    "The goal of this project is to build a classification model that predicts the survival of passengers aboard the Titanic based on the provided features. The project includes data exploration, feature engineering, model building, and evaluation of classification models.\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "- **Model Training**: The objective of model training is to train the model with the dataset so that it can recognise the pattern present in the data so that it can predict the survival of passengers.\n",
    "- **Model Evaluation**: Evaluate the performance of the model with the help of different evaluation metrics such as accuracy, precision, recall and F1 score.\n",
    "- **Model Optimization**: Find the optimal model using cross validation and hyperparameter tuning so that performance of the model is enhanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f237a0f-66c5-4cee-b058-9c6ccb5d5c7c",
   "metadata": {},
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "318caf39-ad5a-4560-a836-23d02a3e134f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Model and Evaluation Metrics\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Model Optimization\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9156e81-c839-49ab-a6d0-f0bab3acba46",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e79d9068-b8f7-4e70-8fa7-50f847f43278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Path\n",
    "data_path = \"../data\"\n",
    "model_path = \"../models\"\n",
    "csv_path = os.path.join(data_path, \"titanic_en.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1556f860-afed-4e7d-869e-4d488b73cb62",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "650857b5-4202-4688-be13-2e5c83b5f91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b33da192-6471-4cfb-a3aa-aed164d60ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Age  SibSp  Parch     Fare  FamilySize  Sex_male  \\\n",
       "0         0       3  22.0      1      0   7.2500           2         1   \n",
       "1         1       1  38.0      1      0  71.2833           2         0   \n",
       "2         1       3  26.0      0      0   7.9250           1         0   \n",
       "3         1       1  35.0      1      0  53.1000           2         0   \n",
       "4         0       3  35.0      0      0   8.0500           1         1   \n",
       "\n",
       "   Embarked_Q  Embarked_S  \n",
       "0           0           1  \n",
       "1           0           0  \n",
       "2           0           1  \n",
       "3           0           1  \n",
       "4           0           1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7654b9c6-d3b3-4f3e-97d8-eea4f6cf7b21",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff0ea49f-e219-4745-a10c-b70c5138cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the Input and Output Features to use in supervised machine learning model\n",
    "X = df.drop(\"Survived\", axis= 1)\n",
    "y =df[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2d7ce26-d1b1-4ddf-a760-6305ed47c781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Train and Test Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48bf18c4-c17f-48c0-8d32-652df0fb1784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data to convert all the data in same scale\n",
    "\n",
    "# Define scaler\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e006b7ae-495d-4c31-a7ca-5eef05c843a0",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d22d2822-c97a-46ed-9197-894c3a587021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to train the model and print the evaluation metrics\n",
    "def train_evaluate(model):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Prediction on train and test data\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Print Evaluation Metrics\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Training Evaluation\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Accuracy: {accuracy_score(y_train, y_train_pred): 0.2f}\")\n",
    "    print(f\"Precision: {precision_score(y_train, y_train_pred):0.2f}\")\n",
    "    print(f\"Recall: {recall_score(y_train, y_train_pred):0.2f}\")\n",
    "    print(f\"F1: {f1_score(y_train, y_train_pred):0.2f}\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Testing Evaluation\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_test_pred): 0.2f}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_test_pred):0.2f}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_test_pred):0.2f}\")\n",
    "    print(f\"F1: {f1_score(y_test, y_test_pred):0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5dc71926-c955-4a7d-b1ce-84e1ace2b4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Training Evaluation\n",
      "============================================================\n",
      "Accuracy:  0.97\n",
      "Precision: 0.98\n",
      "Recall: 0.93\n",
      "F1: 0.95\n",
      "============================================================\n",
      "Testing Evaluation\n",
      "============================================================\n",
      "Accuracy:  0.79\n",
      "Precision: 0.74\n",
      "Recall: 0.76\n",
      "F1: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Try with XGBoost Classifier\n",
    "xgbc = XGBClassifier()\n",
    "train_evaluate(xgbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7b3a7d-ae7d-4565-8710-a8f7f20acaae",
   "metadata": {},
   "source": [
    "### Insights\n",
    "\n",
    "The model's performance on the training data is very high, with an accuracy of **97%**. This suggests that the model is doing an excellent job of predicting the outcomes for the training dataset. The precision of **98%** indicates that most of the predicted survivors are indeed survivors (very few false positives), and the recall of **93%** suggests that the model is able to correctly identify most of the true survivors (few false negatives). The F1-score of **0.95**, which is the harmonic mean of precision and recall, also shows a strong balance between them.\n",
    "\n",
    "On the testing data, the model‚Äôs accuracy drops to **79%**, which is still reasonably good but significantly lower than the training accuracy. The precision (**0.74**) and recall (**0.76**) also show a drop compared to the training set. This indicates that the model is not as effective when dealing with unseen data and may be struggling to generalize the patterns it learned during training.\n",
    "\n",
    "- **Precision**: The value of 0.74 means that when the model predicts someone will survive, **74%** of the time, they actually did survive. The model makes more false positive errors compared to the training data.\n",
    "- **Recall**: The value of **0.76** means that the model is able to identify **76%** of the actual survivors. It‚Äôs missing some survivors (false negatives), meaning it's not as comprehensive in its predictions.\n",
    "- **F1-Score**: This is a balance between precision and recall. While the model is still performing decently, the drop from **0.95** in training to **0.75** in testing reflects the gap in performance, which is a sign of **overfitting**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0c5869-0263-4910-975f-a107fb3c638c",
   "metadata": {},
   "source": [
    "### Model Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39bd15fb-0a69-4ea9-9a6c-b5463ac3f53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross Validation Score:  0.81\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation: Use techniques like k-fold cross-validation to get a better estimate of how the model performs\n",
    "# on unseen data and reduce the chance of overfitting.\n",
    "\n",
    "kf = KFold(n_splits= 5, shuffle= True, random_state= 42)\n",
    "xgbc_cv = XGBClassifier()\n",
    "scores = cross_val_score(xgbc_cv,X, y, cv = kf)\n",
    "\n",
    "print(f\"Mean Cross Validation Score: {scores.mean(): 0.2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69688f06-d7e4-4f23-8e12-9ebc13ef489a",
   "metadata": {},
   "source": [
    "### Insights\n",
    "\n",
    "- The score of **0.81** means that across multiple train-test splits (folds), the model consistently achieves around 81% accuracy.\n",
    "- A mean cross-validation score that is close to your test set accuracy **(0.79)** indicates that the model is performing consistently across different subsets of the data, which is a positive sign. It means the model is less likely to **overfit** or **underfit** to specific parts of the dataset.\n",
    "- If the cross-validation score was much lower or higher than the testing accuracy, it could suggest issues such as **overfitting or data leakage**. However, since **0.81** and **0.79** are quite close, it suggests that your model is generally **reliable and consistent**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c12447b-ddb3-4288-a5e6-d875eeaaa500",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Function to tune the hyperparameter\n",
    "def tune_hyperparameter(model, param_dict):\n",
    "    # Define GridSearchCV\n",
    "    gscv = GridSearchCV(\n",
    "        model,\n",
    "        param_grid= param_dict,\n",
    "        cv = 5,\n",
    "        verbose= 1\n",
    "    )\n",
    "\n",
    "    # Train model the different hyperparameter\n",
    "    gscv.fit(X, y)\n",
    "\n",
    "    # Print best score\n",
    "    print(f\"Best Score: {gscv.best_score_: 0.2f}\")\n",
    "\n",
    "    # Return best hyperparameter set\n",
    "    best_params = gscv.best_params_\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d3a822dc-2016-489f-a522-8d656210ceaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Best Score:  0.85\n",
      "{'alpha': 1, 'colsample_bytree': 1.0, 'gamma': 0, 'labmda': 0, 'max_depth': 8, 'min_child_weight': 3, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter dictionary for XGBoostRegressor\n",
    "param_dict = {\n",
    "    \"n_estimators\": [ 500],\n",
    "    \"max_depth\": [8, 10],\n",
    "    \"min_child_weight\": [3, 5],\n",
    "    \"colsample_bytree\": [0.5, 1.0],\n",
    "    \"alpha\": [0, 1, 2],\n",
    "    \"labmda\": [0, 1],\n",
    "    \"gamma\": [0, 0.1, 1.0]\n",
    "}\n",
    "\n",
    "# Define XGBoost Regressor\n",
    "xgbr_ht = XGBClassifier()\n",
    "\n",
    "# Hyperpermeter tuning to get best hyperparameters\n",
    "best_params = tune_hyperparameter(xgbr_ht, param_dict)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43812a6b-4509-433f-bfa9-9e3f3b33cc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Training Evaluation\n",
      "============================================================\n",
      "Accuracy:  0.92\n",
      "Precision: 0.94\n",
      "Recall: 0.84\n",
      "F1: 0.89\n",
      "============================================================\n",
      "Testing Evaluation\n",
      "============================================================\n",
      "Accuracy:  0.82\n",
      "Precision: 0.81\n",
      "Recall: 0.73\n",
      "F1: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Build with best parameter\n",
    "model = XGBClassifier(**best_params)\n",
    "train_evaluate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df2024f-6b92-48f2-b168-ec2d24d1b8c1",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The results after hyperparameter tuning reflect a more balanced and improved performance, especially in terms of preventing overfitting compared to your previous model. Let‚Äôs break down the performance changes:\n",
    "\n",
    "#### Training Performance:\n",
    "\n",
    "The training evaluation metrics show that the model is performing well on the training data but with slightly lower performance compared to your previous evaluation (where accuracy was **97%**, precision was 98%, and recall was **93%**). This suggests that the model is now less overfitted and more generalizable.\n",
    "\n",
    "- **Precision (0.94)**: The model predicts true positives more accurately, with fewer false positives (i.e., when the model predicts survivors, they are correct 94% of the time).\n",
    "- **Recall (0.84)**: The recall is slightly lower, meaning that 84% of the actual survivors are correctly predicted, but 16% are missed (false negatives).\n",
    "- **F1-Score (0.89)**: The F1-score, balancing precision and recall, is high, showing the model is well-rounded.\n",
    "\n",
    "#### Testing Performance:\n",
    "  \n",
    "After hyperparameter tuning, the testing performance has improved slightly compared to the previous evaluation:\n",
    "\n",
    "- **Accuracy** increased from **79%** to **82%**, which is a sign that the model is better at generalizing to unseen data.\n",
    "- **Precision** improved to **0.81** (previously **0.74**), meaning that the model makes fewer false positive errors on the test set.\n",
    "- **Recall** dropped slightly from **0.76** to **0.73**, meaning the model misses a few more actual positives (survivors) compared to before.\n",
    "- **F1-Score** increased to **0.77** (from **0.75**), indicating an overall improvement in the balance between precision and recall on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b689311-a4c4-421f-9060-ab01f0a9ae83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
